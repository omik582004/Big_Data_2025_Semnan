{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# **Big Data Analysis with Google Colab**\n", "This notebook demonstrates how to handle large datasets using **Pandas** and **Dask** in Google Colab."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Step 1: Install required libraries\n", "!pip install dask"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## **Step 2: Generate a Large Dataset**\n", "We simulate a large dataset with 10 million rows."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "import numpy as np\n", "\n", "# Generate a large dataset with 10 million rows\n", "num_rows = 10_000_000\n", "data = {\n", "    'id': np.arange(1, num_rows + 1),\n", "    'category': np.random.choice(['A', 'B', 'C', 'D'], size=num_rows),\n", "    'value': np.random.rand(num_rows) * 100,\n", "    'date': pd.date_range(start='1/1/2020', periods=num_rows, freq='S')\n", "}\n", "\n", "df = pd.DataFrame(data)\n", "df.to_csv('large_dataset.csv', index=False)\n", "print(\"Dataset saved as 'large_dataset.csv'\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## **Step 3: Load the Large Dataset Using Dask**\n", "Dask allows handling large datasets efficiently."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import dask.dataframe as dd\n", "\n", "# Read the large dataset with Dask\n", "df_dask = dd.read_csv('large_dataset.csv')\n", "\n", "# Display the first few rows\n", "df_dask.head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## **Step 4: Perform Big Data Analysis**"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# 1. Count Rows\n", "df_dask.shape[0].compute()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# 2. Summary Statistics\n", "df_dask.describe().compute()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# 3. Group Data by Category\n", "df_grouped = df_dask.groupby('category')['value'].mean().compute()\n", "print(df_grouped)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# 4. Filter Large Values\n", "df_filtered = df_dask[df_dask['value'] > 90]\n", "df_filtered.compute().head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## **Step 5: Visualizing Data**"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt\n", "\n", "# Convert Dask DataFrame to Pandas for plotting\n", "df_plot = df_grouped.to_frame().reset_index()\n", "\n", "# Bar plot of category-wise average value\n", "plt.figure(figsize=(8, 5))\n", "plt.bar(df_plot['category'], df_plot['value'], color=['blue', 'green', 'red', 'purple'])\n", "plt.xlabel(\"Category\")\n", "plt.ylabel(\"Average Value\")\n", "plt.title(\"Average Value per Category\")\n", "plt.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.10"}}, "nbformat": 4, "nbformat_minor": 4}