{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["<h1 style='color:blue'>\ud83d\udd39 Dask for Big Data Analysis \ud83d\udd39</h1>\n", "\n", "Dask is a **parallel computing** library designed for handling **large datasets** efficiently.\n", "It extends the capabilities of **pandas, NumPy, and scikit-learn** to work with big data."]}, {"cell_type": "markdown", "metadata": {}, "source": ["<h2 style='color:green'>\u2705 Why Use Dask?</h2>\n", "- **Parallel Computing**: Uses multiple CPU cores.\n", "- **Lazy Evaluation**: Computes only when needed.\n", "- **Scalability**: Works on personal machines and clusters.\n", "- **Familiar API**: Similar to pandas and NumPy."]}, {"cell_type": "markdown", "metadata": {}, "source": ["<h2 style='color:purple'>\ud83d\udd39 Step 1: Install Dask</h2>\n", "First, install **Dask** if it's not already installed."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["!pip install dask"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<h2 style='color:purple'>\ud83d\udd39 Step 2: Import Required Libraries</h2>\n", "Now, let's import **Dask DataFrame**, which works like pandas but is optimized for big data."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import dask.dataframe as dd"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<h2 style='color:purple'>\ud83d\udd39 Step 3: Load a Large CSV File</h2>\n", "Instead of loading the entire dataset into memory (as pandas does), **Dask loads it in chunks.**"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Load large dataset (Example: NYC Taxi Data)\n", "df = dd.read_csv('https://people.sc.fsu.edu/~jburkardt/data/csv/hw_200.csv')\n", "\n", "# Display first few rows\n", "df.head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<h2 style='color:purple'>\ud83d\udd39 Step 4: Compute Statistics</h2>\n", "Dask does **lazy evaluation**, meaning it only computes when `.compute()` is called."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Compute summary statistics\n", "df.describe().compute()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<h2 style='color:purple'>\ud83d\udd39 Step 5: Parallel Computation</h2>\n", "Dask runs operations **in parallel** on multiple CPU cores."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Compute mean of a column\n", "df['Height(Inches)'].mean().compute()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<h2 style='color:purple'>\ud83d\udd39 Step 6: Data Visualization</h2>\n", "Dask can also handle big data visualization efficiently."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt\n", "\n", "# Convert to pandas for visualization\n", "df_pd = df.compute()\n", "\n", "# Plot histogram\n", "df_pd.hist(figsize=(8, 5))\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<h2 style='color:blue'>\ud83d\ude80 Conclusion</h2>\n", "- **Dask** helps process large datasets that **don't fit in memory**.\n", "- Works like pandas but processes data **in parallel**.\n", "- **Ideal for Big Data analysis** on personal machines or cloud environments."]}], "metadata": {}, "nbformat": 4, "nbformat_minor": 4}