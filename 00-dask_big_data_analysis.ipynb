{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPs3VAo1FANT"
      },
      "source": [
        "<h1 style='color:blue'>ðŸ”¹ Dask for Big Data Analysis ðŸ”¹</h1>\n",
        "\n",
        "Dask is a **parallel computing** library designed for handling **large datasets** efficiently.\n",
        "It extends the capabilities of **pandas, NumPy, and scikit-learn** to work with big data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-XJ9P-bFANZ"
      },
      "source": [
        "<h2 style='color:green'>âœ… Why Use Dask?</h2>\n",
        "- **Parallel Computing**: Uses multiple CPU cores.\n",
        "- **Lazy Evaluation**: Computes only when needed.\n",
        "- **Scalability**: Works on personal machines and clusters.\n",
        "- **Familiar API**: Similar to pandas and NumPy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VyKwkYqFANa"
      },
      "source": [
        "<h2 style='color:purple'>ðŸ”¹ Step 1: Install Dask</h2>\n",
        "First, install **Dask** if it's not already installed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NuNGr6F_FANc"
      },
      "outputs": [],
      "source": [
        "!pip install dask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zp7vggu5FANf"
      },
      "source": [
        "<h2 style='color:purple'>ðŸ”¹ Step 2: Import Required Libraries</h2>\n",
        "Now, let's import **Dask DataFrame**, which works like pandas but is optimized for big data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GlTxaLHlFANg"
      },
      "outputs": [],
      "source": [
        "import dask.dataframe as dd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JO3Z7LLxFANh"
      },
      "source": [
        "<h2 style='color:purple'>ðŸ”¹ Step 3: Load a Large CSV File</h2>\n",
        "Instead of loading the entire dataset into memory (as pandas does), **Dask loads it in chunks.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "geXPyocuFANi"
      },
      "outputs": [],
      "source": [
        "# Load large dataset (Example: NYC Taxi Data)\n",
        "df = dd.read_csv('https://people.sc.fsu.edu/~jburkardt/data/csv/hw_200.csv')\n",
        "\n",
        "# Display first few rows\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xi-BqRe7FANj"
      },
      "source": [
        "<h2 style='color:purple'>ðŸ”¹ Step 4: Compute Statistics</h2>\n",
        "Dask does **lazy evaluation**, meaning it only computes when `.compute()` is called."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZFO5F7I7FANk"
      },
      "outputs": [],
      "source": [
        "# Compute summary statistics\n",
        "df.describe().compute()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCMOkLXvFANl"
      },
      "source": [
        "<h2 style='color:purple'>ðŸ”¹ Step 5: Parallel Computation</h2>\n",
        "Dask runs operations **in parallel** on multiple CPU cores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BthIvbJMFANm"
      },
      "outputs": [],
      "source": [
        "# Compute mean of a column\n",
        "df['Height(Inches)'].mean().compute()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZrRGjd3FANn"
      },
      "source": [
        "<h2 style='color:purple'>ðŸ”¹ Step 6: Data Visualization</h2>\n",
        "Dask can also handle big data visualization efficiently."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCm6mi7oFANo"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Convert to pandas for visualization\n",
        "df_pd = df.compute()\n",
        "\n",
        "# Plot histogram\n",
        "df_pd.hist(figsize=(8, 5))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDlJ4FG5FANp"
      },
      "source": [
        "<h2 style='color:blue'>ðŸš€ Conclusion</h2>\n",
        "- **Dask** helps process large datasets that **don't fit in memory**.\n",
        "- Works like pandas but processes data **in parallel**.\n",
        "- **Ideal for Big Data analysis** on personal machines or cloud environments."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}